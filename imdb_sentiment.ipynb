{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e50711e-0a1d-461d-92f6-771160233560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7cdf7c-7a0a-4cfb-bc7b-d7fde8c640c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341dfc00-143e-4daf-af3c-3d00a9c728ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "                                                   review sentiment\n",
      "count                                               50000     50000\n",
      "unique                                              49582         2\n",
      "top     Loved today's show!!! It was a variety and not...  positive\n",
      "freq                                                    5     25000\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.isnull().sum())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e408584-dd2d-4692-8f84-d9b92ab83c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\prana\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\prana\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\prana\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\prana\\anaconda3\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\prana\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd61ad7-f432-4b07-96c0-4005148210aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\anaconda3\\envs\\fresh_env\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16ca9d10-c6bf-470e-b5a1-9fe77acfa341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e79bfb4-5c67-4d8e-ae10-170e5ee0ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef181de-ce9a-4501-a068-618f79464090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\prana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have to download the nltk resources\n",
    "#We need stopwords + wordnet lemmatizer.\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8f07156-fc19-43c6-9021-c41bb881eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords removal = remove noisy filler words\n",
    "# Lemmatization = convert words to their meaningful base form\n",
    "# Together they make the text cleaner, more meaningful, and easier for TF-IDF/Word2Vec models to learn from.\n",
    "\n",
    "stop_words=set(stopwords.words('english'))\n",
    "Lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20534542-9f91-42a3-b7f2-2b4f375aa666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing html tag \n",
    "def step_remove_html(text):\n",
    "    return BeautifulSoup(text,\"html.parser\").get_text()\n",
    "\n",
    "# Convert to lowercase \n",
    "def step_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "#Remove punctuations and numbers\n",
    "def step_remove_punc_num(text):\n",
    "    return re.sub(r'[^a-zA-Z]',' ',text)\n",
    "\n",
    "# Tokenize the corpus\n",
    "def step_tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "#Remove stopwords\n",
    "def step_remove_stopwords(words):\n",
    "    return[word for word in words if word not in stop_words]\n",
    "\n",
    "#Lemmatization\n",
    "def step_lemmatize(words):\n",
    "    return [Lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "#Joined back int the full cleaned sentence\n",
    "def step_join(words):\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b23afd49-324d-44fa-a34a-6a3026a1f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we create a clean function that calls all the smaller steps.\n",
    "def clean_text(text):\n",
    "    text=step_remove_html(text)\n",
    "    text=step_lowercase(text)\n",
    "    text=step_remove_punc_num(text)\n",
    "\n",
    "    words=step_tokenize(text)\n",
    "    words=step_remove_stopwords(words)\n",
    "    words=step_lemmatize(words)\n",
    "\n",
    "    return step_join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4ea0b50-34e4-4da1-a7d1-87322a6866b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to the imdb datset we already have\n",
    "\n",
    "df['clean_review']=df['review'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78f06ee4-86a6-4bc7-9d13-aedfd2222c64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>one reviewer mentioned watching oz episode hoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production. <br /><br />The...   \n",
       "2  I thought this was a wonderful way to spend ti...   \n",
       "3  Basically there's a family where a little boy ...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "\n",
       "                                        clean_review  \n",
       "0  one reviewer mentioned watching oz episode hoo...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically family little boy jake think zombie ...  \n",
       "4  petter mattei love time money visually stunnin...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['review','clean_review']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fe1c58d-7760-46db-9ef7-437143496b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  sentiment_label\n",
       "0  positive                1\n",
       "1  positive                1\n",
       "2  positive                1\n",
       "3  negative                0\n",
       "4  positive                1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model A â€” TF-IDF + Logistic Regression\n",
    "#Firsly we are encoding the labels (positive=1, negative=0)\n",
    "\n",
    "df['sentiment_label']=df['sentiment'].map({'positive' : 1,'negative': 0})\n",
    "df[['sentiment','sentiment_label']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72b75c8a-ac43-4802-8016-7e8159959614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test splitiing\n",
    "from sklearn.model_selection import train_test_split\n",
    "x=df['clean_review']\n",
    "y=df['sentiment_label']\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e7c43c8-3ee8-4cfc-b0b0-15435306c3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Vectorizer\n",
    "#This is where my cleaned text gets converted into numerical vectors that ML models can understand.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer(max_features=10000)\n",
    "x_train_tfidf=tfidf.fit_transform(x_train)\n",
    "x_test_tfidf=tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c6cac56-f15a-4403-a585-ebde5c93e0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8945\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89      4961\n",
      "           1       0.88      0.91      0.90      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF vectors are ready, which means we have completed the feature engineering\n",
    "#Train Logistic Regression on TF-IDF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "#Create the model\n",
    "model_tfidf = LogisticRegression(max_iter=200)\n",
    "# Train the model\n",
    "model_tfidf.fit(x_train_tfidf, y_train)\n",
    "# Predict on test set\n",
    "y_pred = model_tfidf.predict(x_test_tfidf)\n",
    "#Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b69690f-4610-4ccc-bf4f-73f3646bc2e0",
   "metadata": {},
   "source": [
    "TF-IDF + Logistic Regression gives a strong baseline accuracy of 89.4% on IMDB reviews.\n",
    "The model performs consistently across both positive and negative classes, with balanced precision, recall, and F1-scores.\n",
    "This establishes a reliable reference point for comparing Word2Vec and LSTM models next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1360351e-e151-42d0-b840-28881e7f372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our own Word2Vec model \n",
    "#converting our cleaned text into tokenized lists.\n",
    "sentences = [review.split() for review in df['clean_review']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6253b038-282c-41a7-be1e-9002223a37ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\prana\\anaconda3\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\prana\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n"
     ]
    }
   ],
   "source": [
    "#Train Word2Vec Model\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3c26a632-6bec-4e5d-a0bd-1e409b8d8915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.4.0-cp39-cp39-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages (from gensim) (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Collecting smart_open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\prana\\anaconda3\\envs\\fresh_env\\lib\\site-packages (from smart_open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.4.0-cp39-cp39-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.3/24.4 MB 9.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.4/24.4 MB 10.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 5.5/24.4 MB 9.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 7.9/24.4 MB 10.1 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.7/24.4 MB 9.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 9.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 9.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 9.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 9.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 10.5/24.4 MB 9.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.4/24.4 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.7/24.4 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.1/24.4 MB 6.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.7/24.4 MB 7.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.6/24.4 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.5.0-py3-none-any.whl (63 kB)\n",
      "Installing collected packages: smart_open, gensim\n",
      "Successfully installed gensim-4.4.0 smart_open-7.5.0\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3688687-8529-4b40-9ee0-9cc8fe3f0dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "w2v_model = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=100,   # embedding size\n",
    "    window=5,          # context window\n",
    "    min_count=2,       # ignore rare words\n",
    "    workers=4,         # CPU cores\n",
    "    sg=1               # 1 = skip-gram, 0 = CBOW\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13f6a0e6-8991-426b-8a5a-9f2075e8f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get vector for each word \n",
    "import numpy as np\n",
    "\n",
    "def get_avg_w2v(words, model, vector_size=100):\n",
    "    vec = np.zeros(vector_size)\n",
    "    count = 0\n",
    "    \n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            vec += model.wv[word]\n",
    "            count += 1\n",
    "    \n",
    "    if count != 0:\n",
    "        vec = vec / count\n",
    "    \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "563647f0-d46b-423b-880e-5fd8c92fdde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert X_train and X_test to lists of tokens\n",
    "x_train_tokens = [text.split() for text in x_train]\n",
    "x_test_tokens = [text.split() for text in x_test]\n",
    "\n",
    "x_train_w2v = np.array([get_avg_w2v(words, w2v_model, 100) for words in x_train_tokens])\n",
    "x_test_w2v = np.array([get_avg_w2v(words, w2v_model, 100) for words in x_test_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "43b9eca5-0358-4abd-9ef2-4b43abe8bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_w2v = LogisticRegression(max_iter=200)\n",
    "model_w2v.fit(x_train_w2v, y_train)\n",
    "\n",
    "y_pred_w2v = model_w2v.predict(x_test_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2258907f-f05b-465a-ab9d-0e1a6e6e04b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      4961\n",
      "           1       0.87      0.88      0.87      5039\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_w2v))\n",
    "print(classification_report(y_test, y_pred_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b9897-1756-42ac-a1c7-2768cc59ffe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fresh_env)",
   "language": "python",
   "name": "fresh_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
